{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nithinivi/Deep_Learning_Discussion/blob/main/001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmSqxL8EiPOm"
   },
   "source": [
    "# Neural Networks\n",
    "\n",
    "Neural networks, a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data\n",
    "\n",
    "\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz12.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyZVNoxBDhah"
   },
   "source": [
    "\n",
    "<img src =\"https://www.codeproject.com/KB/AI/Backprop_ANN/NN2.png\">\n",
    "\n",
    "## relu\n",
    "\n",
    "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOAeVY0Yj7zQ"
   },
   "source": [
    "\n",
    "- Dropout\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hiromis/notes/master/lesson6/6.png\" width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79D3o6bTqaZ8"
   },
   "source": [
    "\n",
    "### Loss\n",
    "\n",
    "- Cross Entropy\n",
    "  \n",
    "  Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of 0.012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0.\n",
    "\n",
    "\n",
    "![neural network](https://ml-cheatsheet.readthedocs.io/en/latest/_images/cross_entropy.png)\n",
    "\n",
    "\\begin{equation}\n",
    "{(y\\log(p) + (1 - y)\\log(1 - p))}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4h2kSn6CvdB"
   },
   "source": [
    "### Softmax\n",
    "\n",
    "The softmax function takes as input a vector z of K real numbers, and normalizes it into a probability distribution consisting of K probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some vector components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval [ 0 , 1 ], and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities. \n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\ \\ \\ \\ \\text{ for } i = 1, \\dotsc , K \\text{ and } \\mathbf z=(z_1,\\dotsc,z_K) \\in R^K.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7R8nJxyA99b"
   },
   "source": [
    "  # optim\n",
    "\n",
    "\n",
    "```\n",
    "  def model(inp):\n",
    "      l1 = inp @ w1 + b1\n",
    "      l2 = relu(l1)\n",
    "      out = l2 @ w2 + b2\n",
    "      return out\n",
    "\n",
    "  def backward pass():\n",
    "  # Back Propagation\n",
    "      mse_grad(out, targ)\n",
    "      lin_grad(l2, out, w2, b2)\n",
    "      relu_grad(l1, l2)\n",
    "      lin_grad(inp, l1, w1, b1)\n",
    "  ```\n",
    "  ```\n",
    "  y_hat = model(xb)\n",
    "  loss = loss_func(y_hat, yb)\n",
    "  backard_pass(y_hat, yb) \n",
    "\n",
    "\n",
    "  for l in model.layers:\n",
    "    l.weight -= l.weight.grad * lr\n",
    "    l.bias   -= l.bias.grad   * lr\n",
    "    l.weight.grad.zero_()\n",
    "    l.bias  .grad.zero_()\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2KaI9znp_sl"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "- SGD\n",
    "\n",
    "Gradient descent is a way to minimize an objective function $J(\\theta)$ parameterized by a model's parameters $\\theta \\in \\mathbb{R}^d$ by updating the parameters in the opposite direction of the gradient of the objective function $\\nabla_\\theta J(\\theta)$ w.r.t. to the parameters. The learning rate $\\eta$ determines the size of the steps we take to reach a  minimum. In other words, we follow the direction of the slope of the surface created by the objective function downhill until we reach a valley.\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J( \\theta)\n",
    "\\end{equation}\n",
    "\n",
    "- Moementum\n",
    "\n",
    "Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations . It does this by adding a fraction $\\gamma$ of the update vector of the past time step to the current update vector\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "v_t &= \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta)\\\\\n",
    "\\theta &= \\theta - v_t\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "The momentum term $\\gamma$ is usually set to $0.9$ or a similar value.\n",
    "\n",
    "Essentially, when using momentum, we push a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way (until it reaches its terminal velocity, if there is air resistance, i.e. $\\gamma < 1$). The same thing happens to our parameter updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.\n",
    "\n",
    "\n",
    "- Adam \n",
    "\n",
    "Adaptive Moment Estimation (Adam) is a method  that calculates  adaptive learning rates for each parameter. Adam stores an exponentially decaying average of past squared gradients $v_t$ l exponentially decaying average of past gradients $m_t$, similar to momentum:\n",
    "\n",
    " we set $g_{t, i}$ to be the gradient of the objective function w.r.t. to the parameter $\\theta_i$ at time step $t$:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "g_{t, i} = \\nabla_{\\theta_t} J( \\theta_{t,i} )\n",
    "\\end{equation}\n",
    "\n",
    "The SGD update for every parameter $\\theta_i$ at each time step $t$ then becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} = \\theta_{t} - \\eta \\cdot g_{t}\n",
    "\\end{equation}\n",
    "   \n",
    "\n",
    "Moving variance $v_t$ and mean $m_t$\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) g_t\\\\\n",
    "v_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "$m_t$ and $v_t$ are estimates of the  mean and variance of the gradients respectively. As $m_t$ and $v_t$ are initialized as vectors of $0$'s, the authors of Adam observe that they are biased towards zero, especially during the initial time steps, and especially when the decay rates are small \n",
    "\n",
    "They counteract these biases by computing bias-corrected first and second moment estimates:\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "\\hat{m}_t &= \\frac{m_t}{1 - \\beta^t_1}\\\\\n",
    "\\hat{v}_t &= \\frac{v_t}{1 - \\beta^t_2}\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "They then use these to update the parameters which yields the Adam update rule:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} = \\theta_{t} - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\hat{m}_t\n",
    "\\end{equation}\n",
    "\n",
    "The authors propose default values of 0.9 for β1, 0.999 for β2, and 10−8\n",
    "for $\\epsilon$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img alt=\"\" class=\"pn ut et fh fd mn v c\" width=\"600\" height=\"458\" role=\"presentation\" src=\"https://miro.medium.com/max/600/1*U224pqhF4WUOZhfmDIWtxA.gif\" srcset=\"https://miro.medium.com/max/276/1*U224pqhF4WUOZhfmDIWtxA.gif 276w, https://miro.medium.com/max/552/1*U224pqhF4WUOZhfmDIWtxA.gif 552w, https://miro.medium.com/max/600/1*U224pqhF4WUOZhfmDIWtxA.gif 600w\" sizes=\"600px\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oJ-HCe6HFEb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEcrz7EW7dpZ",
    "outputId": "1056f6a3-0459-4e0f-a689-6a9b2fcf65e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n",
      "train_images shape: (60000, 28, 28)\n",
      "train_labels shape: (60000,)\n",
      "test_images shape: (10000, 28, 28)\n",
      "test_labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"train_images shape: {}\".format(train_images.shape))\n",
    "print(\"train_labels shape: {}\".format(train_labels.shape))\n",
    "print(\"test_images shape: {}\".format(test_images.shape))\n",
    "print(\"test_labels shape: {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "ukUqtATY7kpQ",
    "outputId": "3d0e9dbe-b8dd-4dc0-db19-a32843da4b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 labels in train_labels: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The first 10 labels in train_labels: {}\".format(train_labels[:10]))\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "for j in range(9):\n",
    "    plt.subplot(3,3, j+1)\n",
    "    plt.imshow(train_images[j],cmap=plt.cm.binary)\n",
    "    plt.tick_params(bottom=False,left=False,labelbottom=False,labelleft=False)\n",
    "    plt.text(0,26,'%d'%train_labels[j])\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqlpkL197qOo"
   },
   "outputs": [],
   "source": [
    "train_images=train_images.reshape((60000, 28*28)) # change the shape\n",
    "train_images=train_images.astype('float32')/255 # normalization\n",
    "\n",
    "test_images=test_images.reshape((10000, 28*28)) # change the shape\n",
    "test_images=test_images.astype('float32')/255 # normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdYCncPT7t7z",
    "outputId": "5a2b78f0-13a4-4900-af85-01bf02a1849e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels shape: \n",
      "test_labels shape: \n",
      "The first 10 rows in the train_labels:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The one-hot encoding will be performed for train_labels and test_label\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(\"train_labels shape: \".format(train_labels.shape))\n",
    "print(\"test_labels shape: \".format(test_labels.shape))\n",
    "\n",
    "print(\"The first 10 rows in the train_labels:\\n{}\".format(train_labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9IVdi4t757i",
    "outputId": "c68f480d-f2b7-4927-f0aa-22d4eb1073df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(16, activation = 'relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(16, activation = 'relu'))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNl7jD6LJzbD",
    "outputId": "c0d531e0-54a2-45a6-c5ae-b4d5d8599a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numeber of parameters for weights first layer :  12560\n",
      "The numeber of parameters for weights second layer :  272\n",
      "The numeber of parameters for weights third layer :  170\n"
     ]
    }
   ],
   "source": [
    "print(\"The numeber of parameters for weights first layer : \", 28*28*16+16)\n",
    "print(\"The numeber of parameters for weights second layer : \", 16*16 + 16)\n",
    "print(\"The numeber of parameters for weights third layer : \", 10*16+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29O1vdqZG3fc",
    "outputId": "43eb4d0f-8ff7-4282-93da-a9c0d0974776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1397 - accuracy: 0.6577\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2981 - accuracy: 0.9173\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2424 - accuracy: 0.9310\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2173 - accuracy: 0.9386\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc655c5dd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.compile(optimizer='adam',\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "                \n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3g49iDGiG8lY",
    "outputId": "e52ce2d3-9eea-4ae2-bd65-922a92eb0860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1994 - accuracy: 0.9429\n",
      "test_loss 0.19937458634376526\n",
      "test_acc:  0.9429000020027161\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(\"test_loss\", test_loss)\n",
    "print(\"test_acc: \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K2RxdRItt0v"
   },
   "source": [
    "# Refernces\n",
    "- http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "- https://arxiv.org/pdf/1609.04747.pdf\n",
    "- http://cs231n.github.io/optimization-1/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "79D3o6bTqaZ8",
    "nmdsdh9xb6x1",
    "nlsHJu9GsWNE",
    "1K2RxdRItt0v"
   ],
   "include_colab_link": true,
   "name": "001.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
